{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRvBMbqZAAh7",
        "outputId": "09a5e48f-3150-4686-e60c-808b8e3dfbcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RNLGI5zAEC5",
        "outputId": "e261a7be-f92f-4c77-eb55-986902ab8103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Baca data CSV\n",
        "df = pd.read_csv('pra-pemrosesan.csv')\n",
        "\n",
        "# Tokenisasi teks\n",
        "#df['Summary'] = df['Summary'].apply(lambda x: x.split())\n",
        "#sentences = df['Summary']\n",
        "sentences = df['Summary'].apply(lambda x: x.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4szZHZQw7h_"
      },
      "outputs": [],
      "source": [
        "# Latih model Word2Vec\n",
        "model = Word2Vec(sentences, vector_size=300, window=3, min_count=7, sg=0, seed=42)\n",
        "\n",
        "# Simpan model Word2Vec ke file jika diperlukan\n",
        "model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muat kembali model jika diperlukan\n",
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "\n",
        "# Ambil daftar semua kata yang direpresentasikan dalam model\n",
        "all_words = list(model.wv.index_to_key)\n",
        "\n",
        "# Simpan vektor ke file .txt\n",
        "with open(\"word_vectors.txt\", \"w\") as file:\n",
        "    for word in all_words:\n",
        "        vector = model.wv[word]\n",
        "        vector_str = \" \".join(map(str, vector))\n",
        "        file.write(f\"{word} {vector_str}\\n\")\n",
        "\n",
        "print(\"Model dan vektor kata telah disimpan ke word_vectors.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DncnDDraeiHe",
        "outputId": "6f86fd36-9683-481d-f57f-17508123a5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dan vektor kata telah disimpan ke word_vectors.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}